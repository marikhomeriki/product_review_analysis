{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c5ea8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e435519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/marikhomeriki/code/marikhomeriki/product_review_analysis/raw_data/train_data/train.csv', header=None)\n",
    "# df_test = pd.read_csv('/Users/marikhomeriki/code/marikhomeriki/product_review_analysis/raw_data/test_data/test.csv', header=None)\n",
    "# df_test = df.rename({0: 'label', 1: 'text'}, axis = 1)\n",
    "df = df.rename({0: 'label', 1: 'text'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6bead00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Unfortunately, the frustration of being Dr. Go...\n",
       "1      2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2      1  I don't know what Dr. Goldberg was like before...\n",
       "3      1  I'm writing this review to give you a heads up...\n",
       "4      2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcac57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bf4bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "def clean (text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fbe6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0851ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04095137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559995</th>\n",
       "      <td>Ryan was as good as everyone on yelp has claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559996</th>\n",
       "      <td>Professional \\nFriendly\\nOn time AND affordabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559997</th>\n",
       "      <td>Phone calls always go to voicemail and message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559998</th>\n",
       "      <td>Looks like all of the good reviews have gone t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559999</th>\n",
       "      <td>Ryan Rocks! I called him this morning for some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       Unfortunately, the frustration of being Dr. Go...\n",
       "1       Been going to Dr. Goldberg for over 10 years. ...\n",
       "2       I don't know what Dr. Goldberg was like before...\n",
       "3       I'm writing this review to give you a heads up...\n",
       "4       All the food is great here. But the best thing...\n",
       "...                                                   ...\n",
       "559995  Ryan was as good as everyone on yelp has claim...\n",
       "559996  Professional \\nFriendly\\nOn time AND affordabl...\n",
       "559997  Phone calls always go to voicemail and message...\n",
       "559998  Looks like all of the good reviews have gone t...\n",
       "559999  Ryan Rocks! I called him this morning for some...\n",
       "\n",
       "[560000 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf8c3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int(10/100*len(df_text['text']))\n",
    "df_text = df_text['text']\n",
    "df_text = df_text[:len_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d0d0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd2a7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['clean_text'] = df_text.text.apply(clean)\n",
    "df_text['clean_text'] = df_text['clean_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37b8c836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "      <td>['unfortunately', 'frustration', 'dr', 'goldbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "      <td>['going', 'dr', 'goldberg', 'year', 'think', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "      <td>['know', 'dr', 'goldberg', 'like', 'moving', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "      <td>['writing', 'review', 'give', 'head', 'see', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "      <td>['food', 'great', 'best', 'thing', 'wing', 'wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55995</th>\n",
       "      <td>I took a party of 6 friends and co-workers the...</td>\n",
       "      <td>['took', 'party', 'friend', 'co', 'worker', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>Stop by for lunch based on Yelp reviews. Tasty...</td>\n",
       "      <td>['stop', 'lunch', 'based', 'yelp', 'review', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>Best persian food ever.\\nWOW!\\n\\nPossibly the ...</td>\n",
       "      <td>['best', 'persian', 'food', 'ever', 'nwow', 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>Habibbbbbb is the rudest, meanest, uglyist, gu...</td>\n",
       "      <td>['habibbbbbb', 'rudest', 'meanest', 'uglyist',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>First if there is a way to give zero stars, I ...</td>\n",
       "      <td>['first', 'way', 'give', 'zero', 'star', 'woul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Unfortunately, the frustration of being Dr. Go...   \n",
       "1      Been going to Dr. Goldberg for over 10 years. ...   \n",
       "2      I don't know what Dr. Goldberg was like before...   \n",
       "3      I'm writing this review to give you a heads up...   \n",
       "4      All the food is great here. But the best thing...   \n",
       "...                                                  ...   \n",
       "55995  I took a party of 6 friends and co-workers the...   \n",
       "55996  Stop by for lunch based on Yelp reviews. Tasty...   \n",
       "55997  Best persian food ever.\\nWOW!\\n\\nPossibly the ...   \n",
       "55998  Habibbbbbb is the rudest, meanest, uglyist, gu...   \n",
       "55999  First if there is a way to give zero stars, I ...   \n",
       "\n",
       "                                              clean_text  \n",
       "0      ['unfortunately', 'frustration', 'dr', 'goldbe...  \n",
       "1      ['going', 'dr', 'goldberg', 'year', 'think', '...  \n",
       "2      ['know', 'dr', 'goldberg', 'like', 'moving', '...  \n",
       "3      ['writing', 'review', 'give', 'head', 'see', '...  \n",
       "4      ['food', 'great', 'best', 'thing', 'wing', 'wi...  \n",
       "...                                                  ...  \n",
       "55995  ['took', 'party', 'friend', 'co', 'worker', 'l...  \n",
       "55996  ['stop', 'lunch', 'based', 'yelp', 'review', '...  \n",
       "55997  ['best', 'persian', 'food', 'ever', 'nwow', 'n...  \n",
       "55998  ['habibbbbbb', 'rudest', 'meanest', 'uglyist',...  \n",
       "55999  ['first', 'way', 'give', 'zero', 'star', 'woul...  \n",
       "\n",
       "[56000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd411451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(df_text['clean_text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=4)\n",
    "\n",
    "lda_vectors = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4a38686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-5 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cba1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0ee6eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('food', 63.17431405324073), ('good', 53.40349980476475), ('great', 42.77701187249921), ('place', 27.43256413107815), ('friendly', 27.246354006460017)]\n",
      "Topic 1:\n",
      "[('place', 54.46623574602995), ('service', 34.73973444795151), ('go', 31.877810293199804), ('back', 25.9231121538039), ('star', 18.24619548584007)]\n",
      "Topic 2:\n",
      "[('back', 30.679256679210262), ('time', 23.9372376271045), ('service', 18.8539950948999), ('place', 15.160167522936261), ('never', 15.037490507307602)]\n",
      "Topic 3:\n",
      "[('food', 42.33094780523769), ('good', 28.617843425717414), ('service', 17.06729557884156), ('better', 16.23645371788231), ('way', 16.19113143368664)]\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f2072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6d879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ea0e7ef60c28ff33ddfdfe82d339f0b9700433ae3bfa8cf7780f713fc04da71b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
