{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bbc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34d4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/marikhomeriki/code/marikhomeriki/product_review_analysis/raw_data/train_data/train.csv', header=None)\n",
    "df_test = pd.read_csv('/Users/marikhomeriki/code/marikhomeriki/product_review_analysis/raw_data/test_data/test.csv', header=None)\n",
    "df_test = df.rename({0: 'label', 1: 'text'}, axis = 1)\n",
    "df = df.rename({0: 'label', 1: 'text'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ec4f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Unfortunately, the frustration of being Dr. Go...\n",
       "1      2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2      1  I don't know what Dr. Goldberg was like before...\n",
       "3      1  I'm writing this review to give you a heads up...\n",
       "4      2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400023eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "def clean (text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaebb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int(10/100*len(df[\"text\"]))\n",
    "train_sentences = df['text'][:len_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56a2ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Unfortunately, the frustration of being Dr. Go...\n",
       "1  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2  I don't know what Dr. Goldberg was like before...\n",
       "3  I'm writing this review to give you a heads up...\n",
       "4  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(train_sentences)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57210b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['clean_text'] = X.text.apply(clean)\n",
    "X['clean_text'] = X['clean_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75304d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(X['clean_text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=8)\n",
    "\n",
    "lda_vectors = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd323053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79df6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('food', 10783.024328373127), ('good', 10605.945704919364), ('place', 8154.214951823843), ('like', 7141.572862050609), ('chicken', 6863.074785821025), ('ordered', 5945.549126061695), ('restaurant', 5793.2713564248015), ('sauce', 5328.974158484404), ('salad', 5103.8994140836), ('one', 4496.946664591148)]\n",
      "Topic 1:\n",
      "[('room', 6058.257138200451), ('one', 3765.445847945894), ('like', 3724.8712833345435), ('place', 3290.165640710726), ('table', 2914.9035745839046), ('would', 2838.5277936559887), ('hotel', 2762.094935183864), ('time', 2485.9198648883926), ('night', 2481.5496341769954), ('back', 2454.270759895313)]\n",
      "Topic 2:\n",
      "[('food', 7869.403975386748), ('good', 7672.397086179339), ('place', 7095.723510417427), ('like', 4664.03065800661), ('get', 3769.5460558355862), ('always', 3538.5093496381105), ('great', 3298.823994222144), ('go', 3253.464811390565), ('love', 3146.2609462008095), ('one', 3109.006891868654)]\n",
      "Topic 3:\n",
      "[('food', 9940.100868407202), ('time', 8614.315990370196), ('service', 8169.448683147333), ('order', 7086.1631424281595), ('back', 5631.709185198796), ('minute', 5469.260447708334), ('get', 5122.26654243824), ('place', 5116.902365571604), ('go', 4745.322357656611), ('pizza', 4616.554907465823)]\n",
      "Topic 4:\n",
      "[('like', 3466.8695050513766), ('place', 3459.358277127258), ('get', 3305.9586038529023), ('store', 3028.83391312287), ('one', 2538.62259271253), ('go', 2371.7426190405818), ('time', 2231.8922552165295), ('really', 2167.6355261769836), ('lot', 2123.1972068567748), ('price', 1930.0545588721711)]\n",
      "Topic 5:\n",
      "[('store', 4360.537272445015), ('one', 3932.2291372186082), ('customer', 3673.6631598489894), ('would', 3178.989700408528), ('time', 2819.197083290728), ('get', 2732.027389641897), ('said', 2384.023986049482), ('back', 2239.031219898368), ('like', 2224.4253812184957), ('service', 2171.4439554476503)]\n",
      "Topic 6:\n",
      "[('great', 9376.440456399338), ('place', 5080.8738950402485), ('bar', 3701.0436687634606), ('service', 2702.410770016234), ('beer', 2702.049108581758), ('food', 2450.3609008750423), ('friendly', 2281.3333929115647), ('staff', 2146.588179542341), ('love', 2144.6436688315425), ('good', 2097.406779136486)]\n",
      "Topic 7:\n",
      "[('car', 5307.116149368164), ('would', 4300.021039492272), ('time', 4040.266189410487), ('get', 3685.698980009207), ('back', 3466.3864556700137), ('told', 3336.013391121583), ('day', 2896.6849409506035), ('service', 2771.9097071953156), ('said', 2500.0078107925574), ('called', 2469.361443347369)]\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f040c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
