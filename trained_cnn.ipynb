{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7832ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "077a38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/marikhomeriki/code/marikhomeriki/product_review_analysis/raw_data/train_data/train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "173d508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/marikhomeriki/code/marikhomeriki/product_review_analysis/raw_data/test_data/test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68c9a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.rename({0: 'label', 1: 'text'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c630eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({0: 'label', 1: 'text'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2f5ee59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Unfortunately, the frustration of being Dr. Go...\n",
       "1      2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2      1  I don't know what Dr. Goldberg was like before...\n",
       "3      1  I'm writing this review to give you a heads up...\n",
       "4      2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a1486f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(data, percentage_of_sentences=None):\n",
    "    \n",
    "    train_sentences = data['text']\n",
    "    y_train = data['label']\n",
    "    \n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "    X_train = [text_to_word_sequence(_) for _ in train_sentences]\n",
    "    \n",
    "  \n",
    "    return X_train, y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d6b8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(df, percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbf4fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data(df_test, percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61f58c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_adj = y_test -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4737e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, maxlen=50, dtype='float32', padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_token, maxlen=50, dtype='float32', padding=\"post\")\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c07db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "def init_cnn_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size + 1, output_dim=20, mask_zero=True, input_length=50))\n",
    "    model.add(layers.Conv1D(32, 3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(50, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_cnn = init_cnn_model(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eff2060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 50, 20)            1378040   \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 48, 32)            1952      \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                76850     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,456,893\n",
      "Trainable params: 1,456,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ec9f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_adj = y_train -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30087e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1225/1225 [==============================] - 14s 5ms/step - loss: 0.3589 - accuracy: 0.8351 - val_loss: 0.2824 - val_accuracy: 0.8826\n",
      "Epoch 2/20\n",
      "1225/1225 [==============================] - 7s 5ms/step - loss: 0.1924 - accuracy: 0.9232 - val_loss: 0.3229 - val_accuracy: 0.8700\n",
      "Epoch 3/20\n",
      "1225/1225 [==============================] - 7s 5ms/step - loss: 0.0789 - accuracy: 0.9707 - val_loss: 0.4508 - val_accuracy: 0.8575\n",
      "Epoch 4/20\n",
      "1225/1225 [==============================] - 6s 5ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.6846 - val_accuracy: 0.8537\n",
      "Epoch 5/20\n",
      "1225/1225 [==============================] - 6s 5ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.9301 - val_accuracy: 0.8450\n",
      "Epoch 6/20\n",
      "1225/1225 [==============================] - 6s 5ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.9433 - val_accuracy: 0.8487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x35af74940>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_cnn.fit(X_train_pad, y_train_adj, \n",
    "          epochs=20, \n",
    "          batch_size=32,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0132dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 1s 505us/step - loss: 0.2230 - accuracy: 0.9138\n"
     ]
    }
   ],
   "source": [
    "res = model_cnn.evaluate(X_test_pad, y_test_adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
